{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model, ensemble\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_validate, ShuffleSplit, GridSearchCV\n",
    "import numpy as np\n",
    "import json\n",
    "from functools import reduce\n",
    "from custom import StratifiedRegressionSplit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real estate prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = pd.read_excel('../data/covariates.xlsx')\n",
    "variables = variables.to_dict(orient='records')\n",
    "targets = []\n",
    "features = []\n",
    "for feature in variables:\n",
    "    feature['type'] = int if feature['type'] == 'int' else float if feature['type'] == 'float' else str\n",
    "    if feature['group'] == 'target':\n",
    "        targets.append(feature)\n",
    "        continue\n",
    "    else:\n",
    "        features.append(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_excel('../data/hp_ljubljana_new_with_rooms.xlsx')\n",
    "feature_names = [x['name'] for x in features]\n",
    "target_names = [x['name'] for x in targets]\n",
    "data = data[feature_names + target_names]\n",
    "\n",
    "\n",
    "exclude_features_names = []\n",
    "categorical_features = [x for x in features if  (x['type'] == str) and (x not in exclude_features_names)]\n",
    "categorical_features_names = [x['name'] for x in categorical_features]\n",
    "numerical_features = [x for x in features if  (x['type'] in (int, float)) and (x not in exclude_features_names)]\n",
    "numerical_features_names = [x['name'] for x in numerical_features]\n",
    "\n",
    "# target = {'name': 'price_m2', 'type': float}\n",
    "\n",
    "onehot = OneHotEncoder(sparse=False)\n",
    "onehot.fit(data[categorical_features_names])\n",
    "encoded_features = list(reduce(lambda x,y: x + y, [[{\"name\": f\"{feature['name']}_{cat}\", \"type\": int, \"group\": feature['group']} for cat in cats] for cats, feature in zip(onehot.categories_, categorical_features)]))\n",
    "encoded_features_names = [x['name'] for x in encoded_features]\n",
    "\n",
    "X_encoded = onehot.transform(data[categorical_features_names])\n",
    "X_numerical = data[numerical_features_names]\n",
    "X = pd.DataFrame(columns=numerical_features_names + encoded_features_names)\n",
    "\n",
    "\n",
    "X[numerical_features_names] = X_numerical\n",
    "X[encoded_features_names] = X_encoded\n",
    "X = X.astype({x['name'] : x['type'] for x in numerical_features + encoded_features})\n",
    "if len(target_names)==1:\n",
    "    y = data[target_names[0]]\n",
    "    y = y.astype({targets[0]['name'] : targets[0]['type']})\n",
    "else:\n",
    "    y = data[target_names]\n",
    "    y = y.astype({x['name'] : x['type'] for x in targets})\n",
    "# # y = (y - y.std())/ y.mean()\n",
    "n_features = len(numerical_features) + len(encoded_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElastiNet Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge = linear_model.Ridge(alpha = 2)\n",
    "def cod(y_true, y_pred):\n",
    "        ratios = np.array(y_pred)/np.array(y_true)\n",
    "        median = np.median(ratios)\n",
    "        abs_dev = np.abs(ratios - median)\n",
    "        return  (100*np.mean(abs_dev))/np.abs(median)\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "        rel_errors = np.abs((np.array(y_true) - np.array(y_pred))/(1e-10 + np.array(y_pred)))\n",
    "        return  100*np.mean(rel_errors)\n",
    "\n",
    "scoring = {'r2': 'r2',\n",
    "           'cod': make_scorer(cod, greater_is_better=False),\n",
    "           'mape': make_scorer(mape, greater_is_better=False)}\n",
    "\n",
    "# gs = GridSearchCV(\n",
    "#         estimator=make_pipeline(StandardScaler(), ensemble.RandomForestRegressor(bootstrap=True, max_features=int(n_features), oob_score=True, n_jobs=-1, random_state = 0)),\n",
    "#         param_grid={'randomforestregressor__n_estimators': list(np.arange(80,110,10))},\n",
    "#         scoring=scoring,\n",
    "#         refit='r2',\n",
    "#         cv=StratifiedRegressionSplit(n_splits=10, n_bins = 10, test_size=0.3, random_state=0)\n",
    "# )\n",
    "\n",
    "strat_split = StratifiedRegressionSplit(n_splits=1, n_bins = 10, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "train, test = next(iter(strat_split.split(X,y)))\n",
    "\n",
    "Xtrain = pd.DataFrame(X.loc[train], columns=X.columns)\n",
    "ytrain = pd.Series(y.loc[train])\n",
    "\n",
    "scaler = StandardScaler().fit(Xtrain)\n",
    "\n",
    "Xtrain = scaler.transform(Xtrain)\n",
    "Xtrain = pd.DataFrame(Xtrain, columns=X.columns)\n",
    "\n",
    "Xtest = pd.DataFrame(X.loc[test], columns=X.columns)\n",
    "ytest = pd.Series(y.loc[test])\n",
    "\n",
    "Xtest = scaler.transform(Xtest)\n",
    "Xtest = pd.DataFrame(Xtest, columns=X.columns)\n",
    "\n",
    "\n",
    "estimator= ensemble.RandomForestRegressor(bootstrap=True, max_features=int(n_features/3), min_samples_split = 4, min_samples_leaf=2, oob_score=True, n_jobs=-1, random_state = 0, n_estimators=500,  max_samples = 0.7)\n",
    "\n",
    "# make_pipeline(, )\n",
    "\n",
    "gs_all_metric_results = estimator.fit(Xtrain, ytrain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results = [{'feature': key, 'importance': value} for key, value in zip(estimator.feature_names_in_, estimator.feature_importances_)]\n",
    "rf_results = sorted(rf_results, key=lambda x: -x['importance'])\n",
    "feature_importances = pd.DataFrame(rf_results)\n",
    "feature_importances.to_excel('../results/randomforest_feature_importances.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"\"\"\n",
    "    EVALUATION METRICS:\n",
    "        Train mean r2: {estimator.score(Xtrain, ytrain)},\n",
    "        Test  mean r2: {estimator.score(Xtest, ytest)},\n",
    "        Train mean cod: {cod(estimator.predict(Xtrain), ytrain)},\n",
    "        Test  mean cod: {cod(estimator.predict(Xtest), ytest)},\n",
    "        Train mean mape: {mape(estimator.predict(Xtrain), ytrain)},\n",
    "        Test mean mape: {mape(estimator.predict(Xtest), ytest)},\n",
    "        \n",
    "    \"\"\"\n",
    ")\n",
    "metrics = {\n",
    "    'train_mean_r2': estimator.score(Xtrain, ytrain),\n",
    "    'test_mean_r2': estimator.score(Xtest, ytest),\n",
    "    'train_mean_cod': cod(estimator.predict(Xtrain), ytrain),\n",
    "    'test_mean_cod': cod(estimator.predict(Xtest), ytest),\n",
    "    'train_mean_mape': mape(estimator.predict(Xtrain), ytrain),\n",
    "    'test_mean_mape': mape(estimator.predict(Xtest), ytest)\n",
    "}\n",
    "with open('../results/randomforest_metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
